{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6987595-996b-4aa8-bf7a-1441c4f5f875",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Ames Housing Dataset\n",
    "\n",
    "## About Dataset\n",
    "The Ames Housing Dataset is a well-known dataset in the field of machine learning and data analysis. It contains various features and attributes of residential homes in Ames, Iowa, USA. The dataset is often used for regression tasks, particularly for predicting housing prices.\n",
    "\n",
    "### Key Details:\n",
    "- **Number of Instances**: The dataset consists of 2,930 instances or observations.\n",
    "- **Number of Features**: There are 79 different features or variables that describe various aspects of the residential properties.\n",
    "- **Target Variable**: The target variable in the dataset is `SalePrice`, representing the sale price of the houses.\n",
    "- **Data Types**:  \n",
    "  - The features include both numerical and categorical variables.\n",
    "  - They cover a wide range of aspects such as lot size, number of rooms, location, construction quality, and more.\n",
    "\n",
    "### Applications:\n",
    "The Ames Housing Dataset is widely used in the machine learning community for:\n",
    "- **Regression Modeling**: Predicting house prices based on property features.\n",
    "- **Feature Engineering**: Developing and testing new techniques to handle numerical and categorical data.\n",
    "- **Predictive Analytics**: Analyzing and forecasting trends in the real estate domain.\n",
    "\n",
    "This dataset serves as a valuable resource for exploring and applying machine learning algorithms to real-world problems related to housing prices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951f4e94-08a8-47f2-a2d3-eb86cc6a1256",
   "metadata": {
    "tags": []
   },
   "source": [
    "# STEP 1: IMPORT LIBRARIES AND SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5f15ae-7a4a-48c4-b443-63d55b1c6a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/03/25 11:46:11] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/03/25 11:46:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=492781;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=298205;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Data Handling & Visualization Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical Functions\n",
    "from scipy.stats import skew\n",
    "\n",
    "# Scikit-learn Libraries for Model Building & Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    mean_squared_error, mean_absolute_error, r2_score\n",
    ")\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "\n",
    "# AWS & SageMaker Libraries for Model Training and Deployment\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Session, get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.amazon.linear_learner import LinearLearner  # SageMaker's built-in Linear Learner algorithm\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter\n",
    "\n",
    "# Additional Libraries\n",
    "from botocore.exceptions import ClientError\n",
    "from typing import Any, List, Union\n",
    "\n",
    "# Logger Setup\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Global Variables\n",
    "file_path = \"AmesHousing.csv\"        # Path to the dataset file\n",
    "original_target_col = \"SalePrice\"    # Name of the original target variable in the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f22376-bc29-4836-ab90-49538541a85e",
   "metadata": {},
   "source": [
    "# STEP 2: LOAD THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdde9798-dcdf-4007-b745-6a34363c46d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "\n",
      "First five rows of the dataset:\n",
      "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
      "0      1  526301100           20        RL         141.0     31770   Pave   \n",
      "1      2  526350040           20        RH          80.0     11622   Pave   \n",
      "2      3  526351010           20        RL          81.0     14267   Pave   \n",
      "3      4  526353030           20        RL          93.0     11160   Pave   \n",
      "4      5  527105010           60        RL          74.0     13830   Pave   \n",
      "\n",
      "  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n",
      "0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
      "1   NaN       Reg          Lvl  ...         0     NaN  MnPrv          NaN   \n",
      "2   NaN       IR1          Lvl  ...         0     NaN    NaN         Gar2   \n",
      "3   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
      "4   NaN       IR1          Lvl  ...         0     NaN  MnPrv          NaN   \n",
      "\n",
      "  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
      "0        0       5    2010       WD           Normal     215000  \n",
      "1        0       6    2010       WD           Normal     105000  \n",
      "2    12500       6    2010       WD           Normal     172000  \n",
      "3        0       4    2010       WD           Normal     244000  \n",
      "4        0       3    2010       WD           Normal     189900  \n",
      "\n",
      "[5 rows x 82 columns]\n",
      "\n",
      "Shape of the dataset: (2930, 82)\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 82 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Order            2930 non-null   int64  \n",
      " 1   PID              2930 non-null   int64  \n",
      " 2   MS SubClass      2930 non-null   int64  \n",
      " 3   MS Zoning        2930 non-null   object \n",
      " 4   Lot Frontage     2440 non-null   float64\n",
      " 5   Lot Area         2930 non-null   int64  \n",
      " 6   Street           2930 non-null   object \n",
      " 7   Alley            198 non-null    object \n",
      " 8   Lot Shape        2930 non-null   object \n",
      " 9   Land Contour     2930 non-null   object \n",
      " 10  Utilities        2930 non-null   object \n",
      " 11  Lot Config       2930 non-null   object \n",
      " 12  Land Slope       2930 non-null   object \n",
      " 13  Neighborhood     2930 non-null   object \n",
      " 14  Condition 1      2930 non-null   object \n",
      " 15  Condition 2      2930 non-null   object \n",
      " 16  Bldg Type        2930 non-null   object \n",
      " 17  House Style      2930 non-null   object \n",
      " 18  Overall Qual     2930 non-null   int64  \n",
      " 19  Overall Cond     2930 non-null   int64  \n",
      " 20  Year Built       2930 non-null   int64  \n",
      " 21  Year Remod/Add   2930 non-null   int64  \n",
      " 22  Roof Style       2930 non-null   object \n",
      " 23  Roof Matl        2930 non-null   object \n",
      " 24  Exterior 1st     2930 non-null   object \n",
      " 25  Exterior 2nd     2930 non-null   object \n",
      " 26  Mas Vnr Type     2907 non-null   object \n",
      " 27  Mas Vnr Area     2907 non-null   float64\n",
      " 28  Exter Qual       2930 non-null   object \n",
      " 29  Exter Cond       2930 non-null   object \n",
      " 30  Foundation       2930 non-null   object \n",
      " 31  Bsmt Qual        2850 non-null   object \n",
      " 32  Bsmt Cond        2850 non-null   object \n",
      " 33  Bsmt Exposure    2847 non-null   object \n",
      " 34  BsmtFin Type 1   2850 non-null   object \n",
      " 35  BsmtFin SF 1     2929 non-null   float64\n",
      " 36  BsmtFin Type 2   2849 non-null   object \n",
      " 37  BsmtFin SF 2     2929 non-null   float64\n",
      " 38  Bsmt Unf SF      2929 non-null   float64\n",
      " 39  Total Bsmt SF    2929 non-null   float64\n",
      " 40  Heating          2930 non-null   object \n",
      " 41  Heating QC       2930 non-null   object \n",
      " 42  Central Air      2930 non-null   object \n",
      " 43  Electrical       2929 non-null   object \n",
      " 44  1st Flr SF       2930 non-null   int64  \n",
      " 45  2nd Flr SF       2930 non-null   int64  \n",
      " 46  Low Qual Fin SF  2930 non-null   int64  \n",
      " 47  Gr Liv Area      2930 non-null   int64  \n",
      " 48  Bsmt Full Bath   2928 non-null   float64\n",
      " 49  Bsmt Half Bath   2928 non-null   float64\n",
      " 50  Full Bath        2930 non-null   int64  \n",
      " 51  Half Bath        2930 non-null   int64  \n",
      " 52  Bedroom AbvGr    2930 non-null   int64  \n",
      " 53  Kitchen AbvGr    2930 non-null   int64  \n",
      " 54  Kitchen Qual     2930 non-null   object \n",
      " 55  TotRms AbvGrd    2930 non-null   int64  \n",
      " 56  Functional       2930 non-null   object \n",
      " 57  Fireplaces       2930 non-null   int64  \n",
      " 58  Fireplace Qu     1508 non-null   object \n",
      " 59  Garage Type      2773 non-null   object \n",
      " 60  Garage Yr Blt    2771 non-null   float64\n",
      " 61  Garage Finish    2771 non-null   object \n",
      " 62  Garage Cars      2929 non-null   float64\n",
      " 63  Garage Area      2929 non-null   float64\n",
      " 64  Garage Qual      2771 non-null   object \n",
      " 65  Garage Cond      2771 non-null   object \n",
      " 66  Paved Drive      2930 non-null   object \n",
      " 67  Wood Deck SF     2930 non-null   int64  \n",
      " 68  Open Porch SF    2930 non-null   int64  \n",
      " 69  Enclosed Porch   2930 non-null   int64  \n",
      " 70  3Ssn Porch       2930 non-null   int64  \n",
      " 71  Screen Porch     2930 non-null   int64  \n",
      " 72  Pool Area        2930 non-null   int64  \n",
      " 73  Pool QC          13 non-null     object \n",
      " 74  Fence            572 non-null    object \n",
      " 75  Misc Feature     106 non-null    object \n",
      " 76  Misc Val         2930 non-null   int64  \n",
      " 77  Mo Sold          2930 non-null   int64  \n",
      " 78  Yr Sold          2930 non-null   int64  \n",
      " 79  Sale Type        2930 non-null   object \n",
      " 80  Sale Condition   2930 non-null   object \n",
      " 81  SalePrice        2930 non-null   int64  \n",
      "dtypes: float64(11), int64(28), object(43)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "def load_data(filepath):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file into a pandas DataFrame.\n",
    "\n",
    "    This function reads the CSV file at the given filepath using pandas' read_csv\n",
    "    method. It is designed to illustrate basic data ingestion and includes error \n",
    "    handling for common issues, such as the file not being found. The error messages\n",
    "    and exception re-raising help users diagnose problems during the loading process.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame containing the loaded data.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the file does not exist at the specified path.\n",
    "        Exception: For any other error that occurs during the file reading.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to read the CSV file into a DataFrame\n",
    "        data = pd.read_csv(filepath)\n",
    "        return data\n",
    "    except FileNotFoundError as e:\n",
    "        # Inform the user that the file was not found and re-raise the exception.\n",
    "        print(f\"Error: The file at '{filepath}' was not found.\")\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        # Handle any other exceptions that might occur during file reading.\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "# Define global variables for file path and target column for ease of modification.\n",
    "file_path = \"AmesHousing.csv\"  # Path to the dataset file\n",
    "target_col = \"SalePrice\"       # The column to be used as the target variable for prediction\n",
    "\n",
    "# Load data using the load_data function.\n",
    "df = load_data(file_path)\n",
    "print(\"Data loaded successfully!\\n\")\n",
    "\n",
    "# Display the first few rows of the dataset to provide a quick visual overview.\n",
    "print(\"First five rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the dimensions of the dataset (number of rows and columns).\n",
    "print(\"\\nShape of the dataset:\", df.shape)\n",
    "\n",
    "# Print detailed information about the dataset, including data types and non-null counts.\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bcf072-cf8f-4b1f-82e7-3bfd2524fa1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# STEP 3: PREPROCESS THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bf7c32-baa2-4a7e-bb88-b189c1954d82",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Drop Columns with Too Many Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249e3590-2b40-49d4-aada-16442a92456f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns with more than 30% missing values: ['Alley', 'Fireplace Qu', 'Pool QC', 'Fence', 'Misc Feature']\n"
     ]
    }
   ],
   "source": [
    "def drop_high_missing_columns(dataframe, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Drop columns from the DataFrame where the fraction of missing values exceeds the specified threshold.\n",
    "\n",
    "    This function calculates the percentage of missing values in each column and removes\n",
    "    those columns where the fraction of missing values is greater than the threshold. \n",
    "    This helps reduce noise and potential bias when features with too many missing values\n",
    "    might negatively impact the model's performance.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame to process.\n",
    "        threshold (float): The maximum allowable fraction of missing values for a column.\n",
    "                           Columns exceeding this threshold will be dropped (default is 0.3).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with columns removed that have more than the allowed missing values.\n",
    "    \"\"\"\n",
    "    # Identify columns where the proportion of missing values exceeds the threshold.\n",
    "    cols_to_drop = dataframe.columns[dataframe.isnull().mean() > threshold]\n",
    "    \n",
    "    # Print out the columns that will be dropped for transparency.\n",
    "    print(f\"Dropping columns with more than {threshold*100:.0f}% missing values: {list(cols_to_drop)}\")\n",
    "    \n",
    "    # Return a new DataFrame with the identified columns removed.\n",
    "    return dataframe.drop(columns=cols_to_drop)\n",
    "\n",
    "\n",
    "# Apply the function to the DataFrame to remove columns with too many missing values.\n",
    "df = drop_high_missing_columns(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64700264-c6a2-47b6-8307-a128351ed8b0",
   "metadata": {},
   "source": [
    "## Drop Rows with Missing Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a494af3-ac51-4a7e-ab87-bad78b835487",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows with missing 'SalePrice'.\n"
     ]
    }
   ],
   "source": [
    "def drop_missing_target(dataframe, target_column):\n",
    "    \"\"\"\n",
    "    Drop rows from the DataFrame where the target variable is missing.\n",
    "\n",
    "    This function checks if the target column exists in the DataFrame.\n",
    "    If it does, rows with missing values in the target column are removed.\n",
    "    This is crucial because missing target values can cause issues during model training,\n",
    "    leading to inaccurate or biased predictions.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame to process.\n",
    "        target_column (str): The name of the target variable column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with rows removed where the target variable is missing.\n",
    "    \"\"\"\n",
    "    # Check if the target column exists in the DataFrame.\n",
    "    if target_column not in dataframe.columns:\n",
    "        print(f\"Target column '{target_column}' not found.\")\n",
    "        return dataframe\n",
    "\n",
    "    # Record the number of rows before dropping missing target values.\n",
    "    before = len(dataframe)\n",
    "    \n",
    "    # Drop rows where the target column has missing values.\n",
    "    dataframe = dataframe.dropna(subset=[target_column])\n",
    "    \n",
    "    # Record the number of rows after the operation.\n",
    "    after = len(dataframe)\n",
    "    \n",
    "    # Inform the user about how many rows were dropped.\n",
    "    print(f\"Dropped {before - after} rows with missing '{target_column}'.\")\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# Apply the function to drop rows with missing values in the target column.\n",
    "df = drop_missing_target(df, target_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fae9cb-ba5f-4d02-a72d-fa5cd519b50d",
   "metadata": {},
   "source": [
    "## Fill Remaining Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71cb7fb6-fc2d-4dd6-9ffc-e6cac1ad25d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_missing_values(dataframe):\n",
    "    \"\"\"\n",
    "    Fill missing values in the DataFrame for both numerical and categorical columns.\n",
    "\n",
    "    For numerical columns, missing values are replaced with the median. The median is \n",
    "    chosen because it is less sensitive to outliers compared to the mean. For categorical \n",
    "    columns, missing values are replaced with the string \"Missing\" to explicitly denote \n",
    "    that data was absent.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame with missing values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with missing values filled in.\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame to avoid modifying the original data.\n",
    "    df_copy = dataframe.copy()\n",
    "\n",
    "    # Identify numerical columns using pandas' select_dtypes method.\n",
    "    numeric_cols = df_copy.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Identify categorical columns (non-numeric) using select_dtypes.\n",
    "    categorical_cols = df_copy.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "    # Fill missing values in numerical columns with the median value of each column.\n",
    "    df_copy[numeric_cols] = df_copy[numeric_cols].fillna(df_copy[numeric_cols].median())\n",
    "    \n",
    "    # Fill missing values in categorical columns with the string 'Missing'.\n",
    "    df_copy[categorical_cols] = df_copy[categorical_cols].fillna(\"Missing\")\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# Apply the fill_missing_values function to the DataFrame.\n",
    "df = fill_missing_values(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1472426a-1af7-4920-b63d-6303dc1ff260",
   "metadata": {},
   "source": [
    "## Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f7a9be4-d6a1-48f1-887e-d0b2f3773d52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 5 outliers from 'Gr Liv Area'.\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers(dataframe, col_name, upper_limit):\n",
    "    \"\"\"\n",
    "    Remove rows from the DataFrame where the values in the specified column exceed the upper_limit.\n",
    "\n",
    "    Outlier removal is crucial to reduce the impact of extreme values that might skew model training.\n",
    "    This function filters the DataFrame, keeping only those rows where the value in the given column\n",
    "    is below the provided upper_limit. If the specified column is not found, it prints a message and returns\n",
    "    the DataFrame unmodified.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame.\n",
    "        col_name (str): The name of the column to inspect for outliers.\n",
    "        upper_limit (float or int): The threshold value; rows with values equal to or above this will be removed.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The filtered DataFrame with outliers removed.\n",
    "    \"\"\"\n",
    "    # Check if the specified column exists in the DataFrame.\n",
    "    if col_name not in dataframe.columns:\n",
    "        print(f\"Column '{col_name}' not found. Skipping outlier removal.\")\n",
    "        return dataframe\n",
    "\n",
    "    # Record the number of rows before removing outliers.\n",
    "    before = len(dataframe)\n",
    "    \n",
    "    # Filter the DataFrame to keep rows where the column value is less than the upper limit.\n",
    "    dataframe = dataframe[dataframe[col_name] < upper_limit]\n",
    "    \n",
    "    # Record the number of rows after filtering.\n",
    "    after = len(dataframe)\n",
    "    \n",
    "    # Inform the user how many rows were removed.\n",
    "    print(f\"Removed {before - after} outliers from '{col_name}'.\")\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# Apply the outlier removal function to the DataFrame.\n",
    "df = remove_outliers(df, col_name=\"Gr Liv Area\", upper_limit=4000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e4316-28f2-4189-bed2-3bea5e473a6f",
   "metadata": {},
   "source": [
    "## Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb9b2bc4-5043-442e-93e7-731eb8d5f86b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_categorical_features(dataframe, freq_threshold=10):\n",
    "    \"\"\"\n",
    "    Encode categorical features in the DataFrame using two strategies:\n",
    "    \n",
    "    - One-hot encoding for categorical variables with a number of unique categories\n",
    "      less than or equal to freq_threshold. One-hot encoding creates binary columns for each\n",
    "      category (dropping the first to avoid multicollinearity).\n",
    "    \n",
    "    - Frequency encoding for categorical variables with more than freq_threshold unique categories.\n",
    "      Frequency encoding replaces each category with its relative frequency in the column.\n",
    "    \n",
    "    This approach helps manage high-cardinality features while still providing useful representations\n",
    "    for variables with fewer categories.\n",
    "    \n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame containing the data.\n",
    "        freq_threshold (int): The maximum number of unique categories for which one-hot encoding is applied.\n",
    "                              Categories with a count greater than this threshold will be frequency encoded.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with categorical features encoded and the original categorical\n",
    "                      columns removed.\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame to avoid modifying the original.\n",
    "    df_copy = dataframe.copy()\n",
    "    \n",
    "    # Identify categorical columns (columns with object type).\n",
    "    cat_cols = df_copy.select_dtypes(include=[\"object\"]).columns\n",
    "    \n",
    "    # List to store DataFrames from one-hot encoding.\n",
    "    one_hot_frames = []\n",
    "    \n",
    "    # Dictionary to store frequency encoded columns.\n",
    "    freq_frames = {}\n",
    "\n",
    "    # Iterate over each categorical column to apply the appropriate encoding.\n",
    "    for col in cat_cols:\n",
    "        unique_count = df_copy[col].nunique()\n",
    "        if unique_count > freq_threshold:\n",
    "            # Frequency encoding: calculate normalized counts (relative frequency).\n",
    "            freq_map = df_copy[col].value_counts(normalize=True)\n",
    "            # Create a new column with the suffix '_freq' for frequency encoded values.\n",
    "            freq_frames[col + \"_freq\"] = df_copy[col].map(freq_map)\n",
    "        else:\n",
    "            # One-hot encoding: create binary columns and drop the first category to avoid multicollinearity.\n",
    "            one_hot_encoded = pd.get_dummies(df_copy[col], prefix=col, drop_first=True)\n",
    "            one_hot_frames.append(one_hot_encoded)\n",
    "\n",
    "    # Merge frequency encoded columns into the DataFrame if any exist.\n",
    "    if freq_frames:\n",
    "        freq_df = pd.DataFrame(freq_frames, index=df_copy.index)\n",
    "        df_copy = df_copy.join(freq_df)\n",
    "    \n",
    "    # Merge one-hot encoded columns into the DataFrame if any exist.\n",
    "    if one_hot_frames:\n",
    "        one_hot_df = pd.concat(one_hot_frames, axis=1)\n",
    "        df_copy = df_copy.join(one_hot_df)\n",
    "\n",
    "    # Drop the original categorical columns since they are now encoded.\n",
    "    df_copy = df_copy.drop(columns=cat_cols)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# Apply the encoding function to the DataFrame.\n",
    "df = encode_categorical_features(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d390c-d6ce-4177-96af-e8e496e10551",
   "metadata": {},
   "source": [
    "# STEP 4: CREATE A BINARY TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23eea87a-6fad-4a95-9af4-7b5f463d283d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target Distribution:\n",
      "Class 0: 1466 samples (50.12%)\n",
      "Class 1: 1459 samples (49.88%)\n",
      "\n",
      "Sample of the Modified Dataset:\n",
      "   Order        PID  MS SubClass  Lot Frontage  Lot Area  Overall Qual  \\\n",
      "0      1  526301100           20         141.0     31770             6   \n",
      "1      2  526350040           20          80.0     11622             5   \n",
      "2      3  526351010           20          81.0     14267             6   \n",
      "3      4  526353030           20          93.0     11160             7   \n",
      "4      5  527105010           60          74.0     13830             5   \n",
      "\n",
      "   Overall Cond  Year Built  Year Remod/Add  Mas Vnr Area  ...  Sale Type_New  \\\n",
      "0             5        1960            1960         112.0  ...              0   \n",
      "1             6        1961            1961           0.0  ...              0   \n",
      "2             6        1958            1958         108.0  ...              0   \n",
      "3             5        1968            1968           0.0  ...              0   \n",
      "4             5        1997            1998           0.0  ...              0   \n",
      "\n",
      "   Sale Type_Oth  Sale Type_VWD  Sale Type_WD   Sale Condition_AdjLand  \\\n",
      "0              0              0              1                       0   \n",
      "1              0              0              1                       0   \n",
      "2              0              0              1                       0   \n",
      "3              0              0              1                       0   \n",
      "4              0              0              1                       0   \n",
      "\n",
      "   Sale Condition_Alloca  Sale Condition_Family  Sale Condition_Normal  \\\n",
      "0                      0                      0                      1   \n",
      "1                      0                      0                      1   \n",
      "2                      0                      0                      1   \n",
      "3                      0                      0                      1   \n",
      "4                      0                      0                      1   \n",
      "\n",
      "   Sale Condition_Partial  AboveMedianPrice  \n",
      "0                       0                 1  \n",
      "1                       0                 0  \n",
      "2                       0                 1  \n",
      "3                       0                 1  \n",
      "4                       0                 1  \n",
      "\n",
      "[5 rows x 204 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the median sale price from the original target column.\n",
    "# This median value acts as a threshold to classify sales.\n",
    "median_price = df[original_target_col].median()\n",
    "\n",
    "# Create a new binary column 'AboveMedianPrice' based on the median:\n",
    "#   - 1 if the sale price is above the median.\n",
    "#   - 0 if the sale price is at or below the median.\n",
    "df[\"AboveMedianPrice\"] = (df[original_target_col] > median_price).astype(int)\n",
    "\n",
    "# Remove the original target column to simplify the dataset for classification.\n",
    "df.drop(columns=[original_target_col], inplace=True)\n",
    "\n",
    "# Update the target column reference for further processing.\n",
    "target_col = \"AboveMedianPrice\"\n",
    "\n",
    "# Print the distribution of the new binary target classes\n",
    "class_counts = df[target_col].value_counts().sort_index()  # Sort for readability\n",
    "class_percentages = (class_counts / len(df)) * 100  # Convert to percentage\n",
    "\n",
    "print(\"\\nTarget Distribution:\")\n",
    "for category, count in class_counts.items():\n",
    "    print(f\"Class {category}: {count} samples ({class_percentages[category]:.2f}%)\")\n",
    "\n",
    "# Print a sample of the modified DataFrame (first 5 rows)\n",
    "print(\"\\nSample of the Modified Dataset:\")\n",
    "print(df.head())  # Display the first few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec5401b-149d-4bb5-8597-f69eaa75b733",
   "metadata": {},
   "source": [
    "# STEP 5: SPLIT THE DATA INTO TRAIN AND VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39b18c3e-f8a8-4800-8095-03d1d78bdaff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: Features (2340, 203), Target (2340,)\n",
      "Validation set: Features (585, 203), Target (585,)\n"
     ]
    }
   ],
   "source": [
    "# Separate the features (X) and the target variable (y).\n",
    "# X contains all columns except the target column.\n",
    "# y contains only the target column.\n",
    "X = df.drop(columns=[target_col])  # Features (predictor variables)\n",
    "y = df[target_col]  # Target variable\n",
    "\n",
    "# Split the data into training and validation sets.\n",
    "# 'test_size=0.2' means 20% of the data is reserved for validation, and 80% for training.\n",
    "# 'random_state=42' ensures that the split remains the same each time the code is run.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and validation sets to confirm successful splitting.\n",
    "print(f\"Training set: Features {X_train.shape}, Target {y_train.shape}\")\n",
    "print(f\"Validation set: Features {X_val.shape}, Target {y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d4f07-ea57-48c4-94c0-343901d4b710",
   "metadata": {},
   "source": [
    "# STEP 6: PREPARE FILES AND SET UP SAGEMAKER SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85445676-d65f-4753-b6d7-b7d751364073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/03/25 11:46:12] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/03/25 11:46:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=149713;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=957175;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/03/25 11:46:13] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/03/25 11:46:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=553481;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=225425;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data uploaded to: s3://sagemaker-us-east-1-785881939712/sagemaker/binary-ames-housing/ames_binary_train.csv\n",
      "Validation data uploaded to: s3://sagemaker-us-east-1-785881939712/sagemaker/binary-ames-housing/ames_binary_validation.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize a SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get IAM role associated with SageMaker\n",
    "role = get_execution_role()\n",
    "\n",
    "# Define S3 bucket, AWS region, and S3 folder prefix for storing data\n",
    "bucket = sagemaker_session.default_bucket()  # Default S3 bucket assigned by SageMaker\n",
    "region = sagemaker_session.boto_region_name  # AWS region of the session\n",
    "prefix = \"sagemaker/binary-ames-housing\"  # Folder path in S3\n",
    "\n",
    "# Combine target labels (y) and feature data (X) for training and validation sets\n",
    "train_data = pd.concat([y_train, X_train], axis=1)\n",
    "validation_data = pd.concat([y_val, X_val], axis=1)\n",
    "\n",
    "# Check for missing values and print a warning if found\n",
    "if train_data.isnull().values.any() or validation_data.isnull().values.any():\n",
    "    print(\"Warning: Missing values detected! Consider handling them before training.\")\n",
    "\n",
    "# Check for class imbalance and print a warning if any class dominates (>75% of the data)\n",
    "train_class_distribution = y_train.value_counts(normalize=True)\n",
    "val_class_distribution = y_val.value_counts(normalize=True)\n",
    "\n",
    "if train_class_distribution.max() > 0.75 or val_class_distribution.max() > 0.75:\n",
    "    print(\"Warning: Class imbalance detected. Consider balancing the dataset.\")\n",
    "\n",
    "# Define filenames for local storage\n",
    "train_file = \"ames_binary_train.csv\"\n",
    "validation_file = \"ames_binary_validation.csv\"\n",
    "\n",
    "# Save training and validation data to CSV files (no headers, no index)\n",
    "train_data.to_csv(train_file, index=False, header=False)\n",
    "validation_data.to_csv(validation_file, index=False, header=False)\n",
    "\n",
    "# Upload datasets to Amazon S3 and retrieve their S3 locations\n",
    "train_uri = sagemaker_session.upload_data(path=train_file, bucket=bucket, key_prefix=prefix)\n",
    "validation_uri = sagemaker_session.upload_data(path=validation_file, bucket=bucket, key_prefix=prefix)\n",
    "\n",
    "# Print the S3 paths of uploaded datasets for reference\n",
    "print(f\"Training data uploaded to: {train_uri}\")\n",
    "print(f\"Validation data uploaded to: {validation_uri}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff46caca-a4dd-43b4-88b1-7c503ed9a837",
   "metadata": {},
   "source": [
    "# STEP 7: TRAIN THE LINEAR LEARNER MODEL WITH HYPERPARAMETER TUNING (BINARY CLASSIFICATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8dd627d-1801-4372-a5f5-eb533a4df5a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/03/25 11:55:36] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Same images used for training and inference. Defaulting to image     <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py#391\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">391</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         scope: inference.                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/03/25 11:55:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Same images used for training and inference. Defaulting to image     \u001b]8;id=105832;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=904881;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py#391\u001b\\\u001b[2m391\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         scope: inference.                                                    \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Ignoring unnecessary instance type: <span style=\"color: #e100e1; text-decoration-color: #e100e1; font-style: italic\">None</span>.                            <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py#528\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">528</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Ignoring unnecessary instance type: \u001b[3;38;2;225;0;225mNone\u001b[0m.                            \u001b]8;id=2803;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=190838;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py#528\u001b\\\u001b[2m528\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No finished training job found associated with this estimator.       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/estimator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">estimator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/estimator.py#1914\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1914</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Please make sure this estimator is only used for building workflow   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         config                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No finished training job found associated with this estimator.       \u001b]8;id=918050;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/estimator.py\u001b\\\u001b[2mestimator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=284786;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/estimator.py#1914\u001b\\\u001b[2m1914\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         Please make sure this estimator is only used for building workflow   \u001b[2m                 \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         config                                                               \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No finished training job found associated with this estimator.       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/estimator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">estimator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/estimator.py#1914\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1914</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Please make sure this estimator is only used for building workflow   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         config                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No finished training job found associated with this estimator.       \u001b]8;id=521194;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/estimator.py\u001b\\\u001b[2mestimator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=95507;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/estimator.py#1914\u001b\\\u001b[2m1914\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         Please make sure this estimator is only used for building workflow   \u001b[2m                 \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         config                                                               \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating hyperparameter tuning job with name:                          <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#3383\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3383</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         linear-learner-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250203</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1155</span>                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating hyperparameter tuning job with name:                          \u001b]8;id=860587;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=775341;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#3383\u001b\\\u001b[2m3383\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         linear-learner-\u001b[1;36m250203\u001b[0m-\u001b[1;36m1155\u001b[0m                                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................................!\n",
      "Hyperparameter tuning job launched!\n"
     ]
    }
   ],
   "source": [
    "# Create TrainingInput objects for tuning\n",
    "train_input = TrainingInput(s3_data=train_uri, content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(s3_data=validation_uri, content_type=\"text/csv\")\n",
    "\n",
    "# Retrieve the container URI for the Linear Learner model.\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    framework=\"linear-learner\",\n",
    "    region=region  # e.g., 'us-east-1'\n",
    ")\n",
    "\n",
    "# Determine the number of features (ensure this is defined using your dataset).\n",
    "num_features = X.shape[1]\n",
    "\n",
    "# Instantiate the SageMaker Estimator for the Linear Learner model.\n",
    "linear_learner = Estimator(\n",
    "    image_uri=container,                        # The container image for Linear Learner.\n",
    "    role=role,                                  # IAM role with necessary permissions.\n",
    "    instance_count=1,                           # Number of instances.\n",
    "    instance_type='ml.m5.large',                # Instance type based on resource needs.\n",
    "    output_path=f's3://{bucket}/{prefix}/output',# S3 bucket & prefix for model artifacts.\n",
    "    sagemaker_session=sagemaker_session         # Active SageMaker session.\n",
    ")\n",
    "\n",
    "# Set fixed hyperparameters.\n",
    "# Note: We leave out mini_batch_size here since we plan to tune it.\n",
    "linear_learner.set_hyperparameters(\n",
    "    feature_dim=num_features,\n",
    "    predictor_type='binary_classifier'\n",
    ")\n",
    "\n",
    "# Define hyperparameter ranges to tune.\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(0.001, 0.1),\n",
    "}\n",
    "\n",
    "# Define the objective metric.\n",
    "# For binary classification with Linear Learner, use 'validation:binary_classification_accuracy'\n",
    "objective_metric_name = \"validation:binary_classification_accuracy\"\n",
    "objective_type = \"Maximize\"\n",
    "\n",
    "# Create the Hyperparameter Tuner.\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=linear_learner,\n",
    "    objective_metric_name=objective_metric_name,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    objective_type=objective_type,\n",
    "    max_jobs=10,            # Total number of training jobs to be run.\n",
    "    max_parallel_jobs=2,     # How many training jobs run in parallel.\n",
    ")\n",
    "\n",
    "# Create TrainingInput objects for tuning.\n",
    "train_input = TrainingInput(s3_data=train_uri, content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(s3_data=validation_uri, content_type=\"text/csv\")\n",
    "\n",
    "# Launch the hyperparameter tuning job.\n",
    "tuner.fit({'train': train_input, 'validation': validation_input})\n",
    "print(\"Hyperparameter tuning job launched!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafe432a-ff53-4f96-bdd5-084bd3ef15d7",
   "metadata": {},
   "source": [
    "# STEP 8: DEPLOY THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecd7c56a-816a-4a0b-9ceb-9efbbebdd36e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/03/25 12:04:04] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint: binary-learner-endpoint-tuned                       <a href=\"file:///tmp/ipykernel_19780/794779235.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">794779235.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_19780/794779235.py#30\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/03/25 12:04:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint: binary-learner-endpoint-tuned                       \u001b]8;id=660593;file:///tmp/ipykernel_19780/794779235.py\u001b\\\u001b[2m794779235.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=144213;file:///tmp/ipykernel_19780/794779235.py#30\u001b\\\u001b[2m30\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint configuration: binary-learner-endpoint-tuned         <a href=\"file:///tmp/ipykernel_19780/794779235.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">794779235.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_19780/794779235.py#42\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">42</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint configuration: binary-learner-endpoint-tuned         \u001b]8;id=520655;file:///tmp/ipykernel_19780/794779235.py\u001b\\\u001b[2m794779235.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=394059;file:///tmp/ipykernel_19780/794779235.py#42\u001b\\\u001b[2m42\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/03/25 12:04:05] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Waiting for endpoint &amp; configuration to be deleted<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                  <a href=\"file:///tmp/ipykernel_19780/794779235.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">794779235.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_19780/794779235.py#52\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/03/25 12:04:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Waiting for endpoint & configuration to be deleted\u001b[33m...\u001b[0m                  \u001b]8;id=301950;file:///tmp/ipykernel_19780/794779235.py\u001b\\\u001b[2m794779235.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=102522;file:///tmp/ipykernel_19780/794779235.py#52\u001b\\\u001b[2m52\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Endpoint or endpoint config still deleting<span style=\"color: #808000; text-decoration-color: #808000\">...</span> sleeping 10s.            <a href=\"file:///tmp/ipykernel_19780/794779235.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">794779235.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_19780/794779235.py#73\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">73</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Endpoint or endpoint config still deleting\u001b[33m...\u001b[0m sleeping 10s.            \u001b]8;id=858408;file:///tmp/ipykernel_19780/794779235.py\u001b\\\u001b[2m794779235.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=318429;file:///tmp/ipykernel_19780/794779235.py#73\u001b\\\u001b[2m73\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/03/25 12:04:15] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Endpoint and endpoint config fully deleted.                            <a href=\"file:///tmp/ipykernel_19780/794779235.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">794779235.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_19780/794779235.py#70\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">70</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/03/25 12:04:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Endpoint and endpoint config fully deleted.                            \u001b]8;id=293636;file:///tmp/ipykernel_19780/794779235.py\u001b\\\u001b[2m794779235.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=284487;file:///tmp/ipykernel_19780/794779235.py#70\u001b\\\u001b[2m70\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-02-03 12:02:39 Starting - Found matching resource for reuse\n",
      "2025-02-03 12:02:39 Downloading - Downloading the training image\n",
      "2025-02-03 12:02:39 Training - Training image download completed. Training in progress.\n",
      "2025-02-03 12:02:39 Uploading - Uploading generated training model\n",
      "2025-02-03 12:02:39 Completed - Resource reused by training job: linear-learner-250203-1155-010-e7ce3e42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/03/25 12:04:20] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: linear-learner-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-02-03-12-04-20-802       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/03/25 12:04:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: linear-learner-\u001b[1;36m2025\u001b[0m-02-03-12-04-20-802       \u001b]8;id=127828;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=944420;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/03/25 12:04:21] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name binary-learner-endpoint-tuned       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#5889\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5889</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/03/25 12:04:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name binary-learner-endpoint-tuned       \u001b]8;id=144617;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=529072;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#5889\u001b\\\u001b[2m5889\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name binary-learner-endpoint-tuned              <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4711\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4711</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name binary-learner-endpoint-tuned              \u001b]8;id=847431;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=865801;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4711\u001b\\\u001b[2m4711\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/03/25 12:08:22] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Best model deployed to endpoint: binary-learner-endpoint-tuned and    <a href=\"file:///tmp/ipykernel_19780/794779235.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">794779235.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_19780/794779235.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         ready for inference.                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/03/25 12:08:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Best model deployed to endpoint: binary-learner-endpoint-tuned and    \u001b]8;id=556271;file:///tmp/ipykernel_19780/794779235.py\u001b\\\u001b[2m794779235.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=467892;file:///tmp/ipykernel_19780/794779235.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         ready for inference.                                                  \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Initialize session and SageMaker client.\n",
    "# -----------------------------------------------------------------------------\n",
    "session = Session()  # High-level SageMaker session\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "# Define a new endpoint name for the tuned model.\n",
    "endpoint_name = \"binary-learner-endpoint-tuned\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. Built-in waiter for InService (helps waiting on creation)\n",
    "# -----------------------------------------------------------------------------\n",
    "endpoint_in_service_waiter = sm_client.get_waiter(\"endpoint_in_service\")\n",
    "\n",
    "def delete_endpoint_and_config(endpoint_name: str, wait_for_deletion: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Deletes an endpoint and its corresponding endpoint configuration (if they exist).\n",
    "    Optionally polls until resources are deleted.\n",
    "    \"\"\"\n",
    "    # 1. Delete endpoint (if it exists).\n",
    "    try:\n",
    "        endpoint_desc = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        endpoint_status = endpoint_desc[\"EndpointStatus\"]\n",
    "\n",
    "        # If the endpoint is Creating or Updating, wait until it becomes InService.\n",
    "        if endpoint_status in (\"Creating\", \"Updating\"):\n",
    "            logger.info(f\"Endpoint '{endpoint_name}' is in '{endpoint_status}' state. Waiting before deletion.\")\n",
    "            endpoint_in_service_waiter.wait(EndpointName=endpoint_name)\n",
    "        \n",
    "        logger.info(f\"Deleting endpoint: {endpoint_name}\")\n",
    "        sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "    except ClientError as e:\n",
    "        if e.response[\"Error\"][\"Code\"] == \"ValidationException\" and \"Could not find\" in e.response[\"Error\"][\"Message\"]:\n",
    "            logger.info(f\"Endpoint '{endpoint_name}' does not exist or has already been deleted.\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # 2. Delete endpoint configuration (if it exists).\n",
    "    try:\n",
    "        sm_client.describe_endpoint_config(EndpointConfigName=endpoint_name)\n",
    "        logger.info(f\"Deleting endpoint configuration: {endpoint_name}\")\n",
    "        sm_client.delete_endpoint_config(EndpointConfigName=endpoint_name)\n",
    "    except ClientError as e:\n",
    "        if e.response[\"Error\"][\"Code\"] == \"ValidationException\" and \"Could not find\" in e.response[\"Error\"][\"Message\"]:\n",
    "            logger.info(f\"Endpoint config '{endpoint_name}' does not exist or has already been deleted.\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # 3. Optionally poll for deletion.\n",
    "    if wait_for_deletion:\n",
    "        logger.info(\"Waiting for endpoint & configuration to be deleted...\")\n",
    "        for _ in range(30):\n",
    "            endpoint_exists = True\n",
    "            endpoint_config_exists = True\n",
    "\n",
    "            try:\n",
    "                sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "            except ClientError as e:\n",
    "                if \"Could not find\" in e.response[\"Error\"][\"Message\"]:\n",
    "                    endpoint_exists = False\n",
    "\n",
    "            try:\n",
    "                sm_client.describe_endpoint_config(EndpointConfigName=endpoint_name)\n",
    "            except ClientError as e:\n",
    "                if \"Could not find\" in e.response[\"Error\"][\"Message\"]:\n",
    "                    endpoint_config_exists = False\n",
    "\n",
    "            if not endpoint_exists and not endpoint_config_exists:\n",
    "                logger.info(\"Endpoint and endpoint config fully deleted.\")\n",
    "                break\n",
    "\n",
    "            logger.info(\"Endpoint or endpoint config still deleting... sleeping 10s.\")\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            logger.warning(\"Endpoint or endpoint config not fully deleted after 30 checks.\")\n",
    "\n",
    "def delete_model(model_name: str, wait_for_deletion: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Deletes a SageMaker model if it exists. Optionally waits until it disappears.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sm_client.describe_model(ModelName=model_name)\n",
    "        logger.info(f\"Deleting model: {model_name}\")\n",
    "        sm_client.delete_model(ModelName=model_name)\n",
    "    except ClientError as e:\n",
    "        if \"Could not find\" in e.response[\"Error\"][\"Message\"]:\n",
    "            logger.info(f\"Model '{model_name}' does not exist or is already deleted.\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    if wait_for_deletion:\n",
    "        for _ in range(20):\n",
    "            try:\n",
    "                sm_client.describe_model(ModelName=model_name)\n",
    "                logger.info(\"Model still deleting... sleeping 5s.\")\n",
    "                time.sleep(5)\n",
    "            except ClientError as e:\n",
    "                if \"Could not find\" in e.response[\"Error\"][\"Message\"]:\n",
    "                    logger.info(\"Model fully deleted.\")\n",
    "                    break\n",
    "        else:\n",
    "            logger.warning(\"Model was not deleted after waiting.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Delete any existing endpoint and configuration with the same name.\n",
    "# -----------------------------------------------------------------------------\n",
    "delete_endpoint_and_config(endpoint_name)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Retrieve the best estimator from the completed tuning job.\n",
    "# -----------------------------------------------------------------------------\n",
    "best_estimator = tuner.best_estimator()  # Assumes that 'tuner' is defined and tuning is complete\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Deploy the best model.\n",
    "# -----------------------------------------------------------------------------\n",
    "predictor = best_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    endpoint_name=endpoint_name\n",
    ")\n",
    "\n",
    "# Set the serializer and deserializer for the predictor.\n",
    "predictor.serializer = CSVSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "logger.info(f\"Best model deployed to endpoint: {endpoint_name} and ready for inference.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d5b7bb-cff1-4517-bdda-5f1c16c08364",
   "metadata": {},
   "source": [
    "# STEP 9: EVALUATE THE DEPLOYED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1e434-21ab-41d1-95a5-ba3dbf74a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_deployed_classifier(predictor, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Evaluate the deployed classification model on the test set.\n",
    "\n",
    "    Fixes:\n",
    "      - Extracts only 'predicted_label'.\n",
    "      - Limits printed output for readability.\n",
    "      - Handles unexpected response formats safely.\n",
    "\n",
    "    Parameters:\n",
    "      predictor: SageMaker Predictor object for the deployed model.\n",
    "      X_val (pd.DataFrame): Test features.\n",
    "      y_val (pd.Series): True labels.\n",
    "\n",
    "    Returns:\n",
    "      dict: Evaluation metrics (Accuracy, Precision, Recall, F1 Score)\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the predictor uses the correct serialization\n",
    "    predictor.serializer = CSVSerializer()\n",
    "\n",
    "    # Copy test features and labels\n",
    "    X_test = X_val.copy()\n",
    "    y_test = y_val.copy()\n",
    "\n",
    "    # Get predictions from the deployed endpoint\n",
    "    predictions = predictor.predict(X_test.values)\n",
    "\n",
    "    # Ensure correct extraction of predicted labels\n",
    "    try:\n",
    "        predicted_labels = [int(result[\"predicted_label\"]) for result in predictions[\"predictions\"]]\n",
    "    except (KeyError, TypeError) as e:\n",
    "        print(f\"Error extracting predictions: {e}\")\n",
    "        return None  # Stop execution if predictions are not correctly formatted\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    acc = accuracy_score(y_test, predicted_labels)\n",
    "    prec = precision_score(y_test, predicted_labels, zero_division=0)\n",
    "    rec = recall_score(y_test, predicted_labels, zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, zero_division=0)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(\"\\n **Evaluation Metrics:**\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\\n\")\n",
    "\n",
    "    # Print detailed classification report\n",
    "    print(\"**Classification Report:**\")\n",
    "    print(classification_report(y_test, predicted_labels))\n",
    "\n",
    "    # Compute and visualize the confusion matrix\n",
    "    cm = confusion_matrix(y_test, predicted_labels)\n",
    "    print(\"\\n**Confusion Matrix (Raw Values):**\")\n",
    "    print(cm)\n",
    "\n",
    "    # Confusion Matrix with percentages for better readability\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # Normalize per class\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm_percent, annot=True, fmt=\".2%\", cmap=\"Blues\",\n",
    "                xticklabels=[\"Below Median\", \"Above Median\"],\n",
    "                yticklabels=[\"Below Median\", \"Above Median\"])\n",
    "    plt.title(\"Confusion Matrix (Percentage)\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.show()\n",
    "\n",
    "    # Return computed evaluation metrics\n",
    "    return {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    }\n",
    "\n",
    "# Example call:\n",
    "# Replace 'predictor', 'X_val', and 'y_val' with actual objects\n",
    "metrics = evaluate_deployed_classifier(predictor, X_val, y_val)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a3b70-da59-4b6c-85c4-b1f4b134df41",
   "metadata": {
    "tags": []
   },
   "source": [
    "# STEP 10: QUERY THE DEPLOYED ENDPOINT WITH TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6626a089-d999-45fa-bdf0-17c2aa8f8a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module: Model Prediction and Evaluation for Binary Classification using SageMaker Predictor\n",
    "\n",
    "This module shows how to obtain predictions from a deployed SageMaker predictor for a binary classification task.\n",
    "It selects the first 5 rows from the test set, sends them to the endpoint in CSV format,\n",
    "extracts the predicted probabilities, converts them to binary labels using a threshold, and compares the predictions\n",
    "with the actual target values.\n",
    "\"\"\"\n",
    "\n",
    "# Select the first 5 rows from the test set for evaluation.\n",
    "sample_data = X_val.head(5)\n",
    "\n",
    "# Convert the selected data to a NumPy array.\n",
    "# This format is required by the predictor's CSVSerializer.\n",
    "input_data = sample_data.values\n",
    "\n",
    "# Request predictions from the deployed endpoint using the sample data.\n",
    "predictions = predictor.predict(input_data)\n",
    "\n",
    "# Process the response if it contains the 'predictions' key.\n",
    "if \"predictions\" in predictions:\n",
    "    # Extract the predicted probabilities from each result.\n",
    "    y_pred_test_probs = [float(result[\"score\"]) for result in predictions[\"predictions\"]]\n",
    "    \n",
    "    # Define a threshold to convert probabilities into binary class labels.\n",
    "    threshold = 0.5\n",
    "    # Convert probabilities to binary labels: 1 if above the threshold, else 0.\n",
    "    y_pred_test_classes = [1 if prob > threshold else 0 for prob in y_pred_test_probs]\n",
    "    \n",
    "    print(\"\\nTest Probabilities on 5 samples:\", y_pred_test_probs)\n",
    "    print(\"Test Predicted Classes on 5 samples:\", y_pred_test_classes)\n",
    "else:\n",
    "    print(\"No 'predictions' key found in the response:\", predictions)\n",
    "\n",
    "# Retrieve the actual target values for the selected sample data.\n",
    "sample_targets = y_val.loc[sample_data.index]\n",
    "print(\"Actual:\", sample_targets.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a101c07-ab68-4939-a49e-43c3786011d8",
   "metadata": {},
   "source": [
    "# STEP 11: DELETE THE ENDPOINT AND ENDPOINT CONFIG (OPTIONAL CLEANUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c04ac6-78b7-4741-b606-cf086a550f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module: SageMaker Endpoint and Configuration Deletion\n",
    "\n",
    "This module defines a function to delete a SageMaker endpoint and its corresponding endpoint configuration.\n",
    "It first attempts to describe each resource to verify its existence, then deletes it if found.\n",
    "If a resource is not found, it prints a message indicating so and continues without raising an error.\n",
    "\"\"\"\n",
    "\n",
    "def delete_sagemaker_endpoint_and_config(sm_client, endpoint_name, endpoint_config_name):\n",
    "    \"\"\"\n",
    "    Delete a SageMaker endpoint and its configuration if they exist.\n",
    "\n",
    "    Parameters:\n",
    "        sm_client: Boto3 client for SageMaker.\n",
    "        endpoint_name (str): The name of the endpoint to delete.\n",
    "        endpoint_config_name (str): The name of the endpoint configuration to delete.\n",
    "    \"\"\"\n",
    "    # Delete the endpoint.\n",
    "    try:\n",
    "        # Attempt to describe the endpoint to check if it exists.\n",
    "        sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        # If no exception, proceed to delete the endpoint.\n",
    "        sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "        print(f\"Deleted endpoint: {endpoint_name}\")\n",
    "    except sm_client.exceptions.ClientError as e:\n",
    "        # If the endpoint is not found, inform the user and continue.\n",
    "        if \"Could not find endpoint\" in str(e) or \"ResourceNotFound\" in str(e):\n",
    "            print(f\"Endpoint '{endpoint_name}' does not exist.\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # Delete the endpoint configuration.\n",
    "    try:\n",
    "        # Attempt to describe the endpoint configuration to check if it exists.\n",
    "        sm_client.describe_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "        # If no exception, proceed to delete the endpoint configuration.\n",
    "        sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "        print(f\"Deleted endpoint config: {endpoint_config_name}\")\n",
    "    except sm_client.exceptions.ClientError as e:\n",
    "        # If the endpoint configuration is not found, inform the user and continue.\n",
    "        if \"Could not find endpoint configuration\" in str(e) or \"ResourceNotFound\" in str(e):\n",
    "            print(f\"Endpoint config '{endpoint_config_name}' does not exist.\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "# Automatically delete the endpoint and its configuration.\n",
    "#delete_sagemaker_endpoint_and_config(sm_client, endpoint_name, endpoint_config_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053188a-013c-421a-969c-fe6048aba2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3e6bc1-142b-45b0-abd5-5b4e917bced7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed6920e-3dcd-48cf-ac3b-f621b6d61fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2033d10-2081-4aa8-8ccf-a6012c42e8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
